{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress copy warning.\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shell_do(command, log=False, return_log=False):\n",
    "    print(f'Executing: {(\" \").join(command.split())}', file=sys.stderr)\n",
    "\n",
    "    res=subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
    "\n",
    "    if log:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if return_log:\n",
    "        return(res.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = '/YOUR/DIRECTORY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a short template for how CNV_finder can be used when a broader data release is available for exploration of highly probable CNV samples within specific cohorts and regions of interest. More customizable argument flags are avaiable to use or are coming soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find studies in data release\n",
    "master_path = '/YOUR/MASTER/PATH'\n",
    "master = pd.read_csv(master_path)\n",
    "print(master.study.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "study = 'LCC' # 'all' for no specified cohort\n",
    "interval = 'PARK2' # if no interval name can provide chr and positions\n",
    "\n",
    "model = 'del' # 'del' or 'dup'\n",
    "window_count = 50 # del: 50; dup: 70\n",
    "split = 5 # del: 5; dup: 10\n",
    "\n",
    "cpus = 8\n",
    "size = len(master[master.study == study])\n",
    "out_dir = f'{wd}/testing/{model}/{study}/{interval}'\n",
    "out_path = f'{out_dir}/GP2_{study}_{interval}'\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'python CNV_modules/run_data_prep.py \\\n",
    "--interval_name {interval} \\\n",
    "--study_name {study} \\\n",
    "--split_interval {split} \\\n",
    "--total_windows {window_count} \\\n",
    "--master_file {master_path} \\\n",
    "--cpus {cpus} \\\n",
    "--out_path {out_path} \\\n",
    "--create_testing \\\n",
    "--test_size {size}' # currently acts as max test size b/c of potential for missing snp metric files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: swarm -f swarm/data_prep.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/data_prep_{model}_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/data_prep_{model}_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/data_prep_{model}_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/data_prep_{model}_{study}_{interval}.swarm --g 200 --time=24:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to run pre-saved models - can use prelim, updated, or final models with same flags\n",
    "if model == 'del':\n",
    "    cmd = f'python CNV_modules/run_lstm_model.py \\\n",
    "    --test_file {out_path}_samples_windows.csv \\\n",
    "    --feature_names dosage_interval dosage_full {model}_dosage_full {model}_dosage_interval std_baf std_mid_baf std_lrr iqr_baf iqr_mid_baf iqr_lrr avg_baf avg_mid_baf avg_lrr \\\n",
    "    --model_file {wd}/ref_files/final_{model}_{split}_{window_count}_combo4_overlapping_binary_lstm_windows.keras \\\n",
    "    --predict \\\n",
    "    --print_summary \\\n",
    "    --out_path {out_path}'\n",
    "\n",
    "elif model == 'dup':\n",
    "    cmd = f'python CNV_modules/run_lstm_model.py \\\n",
    "    --test_file {out_path}_samples_windows.csv \\\n",
    "    --feature_names dosage_interval {model}_dosage_full std_baf std_mid_baf std_lrr iqr_baf iqr_mid_baf iqr_lrr avg_baf avg_mid_baf avg_lrr \\\n",
    "    --model_file {wd}/ref_files/final_{model}_{split}_{window_count}_combo6_overlapping_binary_lstm_windows.keras \\\n",
    "    --predict \\\n",
    "    --print_summary \\\n",
    "    --out_path {out_path}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: swarm -f swarm/ml_model.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/ml_model_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/ml_model_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/ml_model_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/ml_model_{study}_{interval}.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Prep & Local Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier transfer from HPC to local app folder for Streamlit visuals\n",
    "app_dir = f'{out_dir}/app'\n",
    "app_out = f'{app_dir}/GP2_{study}_{interval}'\n",
    "\n",
    "os.makedirs(app_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'python CNV_modules/run_app_prep.py \\\n",
    "--interval_name {interval} \\\n",
    "--test_set_ids {out_path}_testing_IDs.csv \\\n",
    "--test_set_windows {out_path}_samples_windows.csv \\\n",
    "--test_set_results {out_path}_{window_count}_windows_results.csv \\\n",
    "--cpus {cpus} \\\n",
    "--out_path {app_out} \\\n",
    "--make_app_ready'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: swarm -f swarm/app_prep.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/app_prep_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/app_prep_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/app_prep_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/app_prep_{study}_{interval}.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to local for app\n",
    "! scp {app_dir} CNV_app/data/{model}_final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run app code\n",
    "! streamlit run CNV_app/Home.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
