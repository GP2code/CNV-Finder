{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import subprocess"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Supress copy warning.\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def shell_do(command, log=False, return_log=False):\n",
    "    print(f'Executing: {(\" \").join(command.split())}', file=sys.stderr)\n",
    "\n",
    "    res=subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
    "\n",
    "    if log:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if return_log:\n",
    "        return(res.stdout.decode('utf-8'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "wd = '/YOUR/DIRECTORY'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is a short template for how CNV_finder can be used when a broader data release is available for exploration of highly probable CNV samples within specific cohorts and regions of interest. More customizable argument flags are avaiable to use or are coming soon!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Path Set-Up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Find studies in data release\n",
    "master_path = '/YOUR/MASTER/PATH'\n",
    "master = pd.read_csv(master_path)\n",
    "print(master.study.value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set up paths\n",
    "study = 'LCC' # 'all' for no specified cohort\n",
    "interval = 'PARK2' # if no interval name can provide chr and positions\n",
    "\n",
    "model = 'del' # 'del' or 'dup'\n",
    "window_count = 50 # del: 50; dup: 70\n",
    "split = 5 # del: 5; dup: 10\n",
    "\n",
    "cpus = 8\n",
    "size = len(master[master.study == study])\n",
    "out_dir = f'{wd}/testing/{model}/{study}/{interval}'\n",
    "out_path = f'{out_dir}/GP2_{study}_{interval}'\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML Data Prep"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "cmd = f'python run_data_prep.py \\\n",
    "--interval_name {interval} \\\n",
    "--study_name {study} \\\n",
    "--split_interval {split} \\\n",
    "--total_windows {window_count} \\\n",
    "--master_file {master_path} \\\n",
    "--cpus {cpus} \\\n",
    "--out_path {out_path} \\\n",
    "--create_testing \\\n",
    "--test_size {size}' # currently acts as max test size b/c of potential for missing snp metric files"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/data_prep_{model}_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/data_prep_{model}_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/data_prep_{model}_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/data_prep_{model}_{study}_{interval}.swarm --g 200 --time=24:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Executing: swarm -f swarm/data_prep.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# parameters to run pre-saved models - can use prelim, updated, or final models with same flags\n",
    "if model == 'del':\n",
    "    cmd = f'python run_lstm_model.py \\\n",
    "    --test_file {out_path}_samples_windows.csv \\\n",
    "    --feature_names dosage_interval dosage_full {model}_dosage_full {model}_dosage_interval std_baf std_mid_baf std_lrr iqr_baf iqr_mid_baf iqr_lrr avg_baf avg_mid_baf avg_lrr \\\n",
    "    --model_file {wd}/ref_files/final_{model}_{split}_{window_count}_combo4_overlapping_binary_lstm_windows.keras \\\n",
    "    --predict \\\n",
    "    --print_summary \\\n",
    "    --out_path {out_path}'\n",
    "\n",
    "elif model == 'dup':\n",
    "    cmd = f'python run_lstm_model.py \\\n",
    "    --test_file {out_path}_samples_windows.csv \\\n",
    "    --feature_names dosage_interval {model}_dosage_full std_baf std_mid_baf std_lrr iqr_baf iqr_mid_baf iqr_lrr avg_baf avg_mid_baf avg_lrr \\\n",
    "    --model_file {wd}/ref_files/final_{model}_{split}_{window_count}_combo6_overlapping_binary_lstm_windows.keras \\\n",
    "    --predict \\\n",
    "    --print_summary \\\n",
    "    --out_path {out_path}'  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/ml_model_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/ml_model_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/ml_model_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/ml_model_{study}_{interval}.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Executing: swarm -f swarm/ml_model.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### App Prep & Local Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# For easier transfer from HPC to local app folder for Streamlit visuals\n",
    "app_dir = f'{out_dir}/app'\n",
    "app_out = f'{app_dir}/GP2_{study}_{interval}'\n",
    "\n",
    "os.makedirs(app_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "cmd = f'python run_app_prep.py \\\n",
    "--interval_name {interval} \\\n",
    "--test_set_ids {out_path}_testing_IDs.csv \\\n",
    "--test_set_windows {out_path}_samples_windows.csv \\\n",
    "--test_set_results {out_path}_{window_count}_windows_results.csv \\\n",
    "--cpus {cpus} \\\n",
    "--out_path {app_out} \\\n",
    "--make_app_ready'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Launch a job with your HPC\n",
    "conda_env = 'python_3_9'\n",
    "\n",
    "with open(f'swarm/app_prep_{study}_{interval}.sh', 'w') as f:\n",
    "    f.write('#!/usr/bin/env bash\\n\\n')\n",
    "    f.write('source /data/$USER/conda/etc/profile.d/conda.sh\\n')\n",
    "    f.write(f'conda activate {conda_env}\\n')\n",
    "    f.write(cmd)\n",
    "    f.close()\n",
    "    \n",
    "with open(f'swarm/app_prep_{study}_{interval}.swarm', 'w') as f:\n",
    "    f.write(f'bash swarm/app_prep_{study}_{interval}.sh')\n",
    "    f.close()\n",
    "    \n",
    "swarm_cmd = f'swarm -f swarm/app_prep_{study}_{interval}.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9'\n",
    "shell_do(swarm_cmd)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Executing: swarm -f swarm/app_prep.swarm --g 200 --time=2:00:00 --logdir swarm/logs --module python/3.9\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copy files to local for app\n",
    "! scp {app_dir} CNV_app/data/{model}_final_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run app code\n",
    "! streamlit run CNV_app/Home.py"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}